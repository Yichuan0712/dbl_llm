{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CpoGj0xbEkfP"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "if not os.path.ismount('/content/drive'):\n",
        "    drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/drive/MyDrive/.ssh/ ~/\n",
        "!ls ~/.ssh/ -a\n",
        "!ssh -T git@github.com\n",
        "!git clone git@github.com:Yichuan0712/dbl_llm.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JmUL2ypsE0Ra",
        "outputId": "d5998faf-f2e1-473c-d303-8d2a9e071cfa"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".  ..  github_id_rsa  hellbender_id_rsa  id_rsa  id_rsa.pub  known_hosts\n",
            "Hi Yichuan0712! You've successfully authenticated, but GitHub does not provide shell access.\n",
            "Cloning into 'dbl_llm'...\n",
            "remote: Enumerating objects: 60, done.\u001b[K\n",
            "remote: Counting objects: 100% (60/60), done.\u001b[K\n",
            "remote: Compressing objects: 100% (49/49), done.\u001b[K\n",
            "remote: Total 60 (delta 14), reused 56 (delta 10), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (60/60), 2.93 MiB | 5.03 MiB/s, done.\n",
            "Resolving deltas: 100% (14/14), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/OSU/yichuan_gemini.env /content/.env\n",
        "!cp /content/drive/MyDrive/OSU/ngrok_authtoken.txt /content/dbl_llm/ngrok_authtoken.txt"
      ],
      "metadata": {
        "id": "vRpECz0nkCyW"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok -q\n",
        "!pip install python-dotenv -q\n",
        "!pip install fake_useragent -q\n",
        "!pip install shortuuid -q\n",
        "!pip install ratelimit -q\n",
        "!pip install langchain-openai -q\n",
        "!pip install -U langchain-google-genai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XZmlNGjzHCyB",
        "outputId": "575dd214-0c15-4856-ad56-9b0ef4ee8a99"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/125.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m122.9/125.8 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.8/125.8 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for ratelimit (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: Could not find a version that satisfies the requirement request (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for request\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-2.1.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from langchain-google-genai)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting google-ai-generativelanguage<0.7.0,>=0.6.16 (from langchain-google-genai)\n",
            "  Downloading google_ai_generativelanguage-0.6.17-py3-none-any.whl.metadata (9.8 kB)\n",
            "Collecting langchain-core<0.4.0,>=0.3.47 (from langchain-google-genai)\n",
            "  Downloading langchain_core-0.3.47-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: pydantic<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai) (2.10.6)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (2.24.2)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (5.29.3)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.47->langchain-google-genai) (0.3.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.47->langchain-google-genai) (9.0.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.47->langchain-google-genai) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.47->langchain-google-genai) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.47->langchain-google-genai) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.47->langchain-google-genai) (4.12.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain-google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain-google-genai) (2.27.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (1.69.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (2.32.3)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (1.71.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (1.71.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (4.9)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.47->langchain-google-genai) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.47->langchain-google-genai) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.47->langchain-google-genai) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.47->langchain-google-genai) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.47->langchain-google-genai) (0.23.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.47->langchain-google-genai) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.47->langchain-google-genai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.47->langchain-google-genai) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.47->langchain-google-genai) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.47->langchain-google-genai) (0.14.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (2.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.47->langchain-google-genai) (1.3.1)\n",
            "Downloading langchain_google_genai-2.1.1-py3-none-any.whl (40 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading google_ai_generativelanguage-0.6.17-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.47-py3-none-any.whl (417 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.1/417.1 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: filetype, langchain-core, google-ai-generativelanguage, langchain-google-genai\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.45\n",
            "    Uninstalling langchain-core-0.3.45:\n",
            "      Successfully uninstalled langchain-core-0.3.45\n",
            "  Attempting uninstall: google-ai-generativelanguage\n",
            "    Found existing installation: google-ai-generativelanguage 0.6.15\n",
            "    Uninstalling google-ai-generativelanguage-0.6.15:\n",
            "      Successfully uninstalled google-ai-generativelanguage-0.6.15\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-generativeai 0.8.4 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.17 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed filetype-1.2.0 google-ai-generativelanguage-0.6.17 langchain-core-0.3.47 langchain-google-genai-2.1.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "262848ede3654eacaaef183184ee7c19"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "# import google.generativeai as genai\n",
        "# if \"GEMINI_15_API_KEY\" in os.environ:\n",
        "#     genai.configure(api_key=os.environ.get(\"GEMINI_15_API_KEY\", None))"
      ],
      "metadata": {
        "id": "c8vRij6OkHkJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b8f555a-4a0e-431c-e4f5-2a5d76a5fa68"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/dbl_llm')"
      ],
      "metadata": {
        "id": "nMu9qgHqG90s"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from extractor.article_retriever import ArticleRetriever\n",
        "from extractor.html_table_extractor import HtmlTableExtractor\n",
        "import os\n",
        "import time\n",
        "import re\n",
        "import requests\n",
        "from pydantic import BaseModel\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.output_parsers import OutputFixingParser, PydanticOutputParser\n",
        "from langchain.chains import LLMChain\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from bs4 import BeautifulSoup\n",
        "# from content_extractor import extract_article_content\n",
        "# from prompt import prompt_test, generate_prompt_with_uniprot_ids"
      ],
      "metadata": {
        "id": "RhUf6HmvKoO9"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_abstract(html):\n",
        "    soup = BeautifulSoup(html, 'html.parser')\n",
        "\n",
        "    article_section = soup.find('section', {'class': 'abstract'})\n",
        "\n",
        "    if article_section:\n",
        "        return '\\n'.join([p.get_text() for p in article_section.find_all('p')])\n",
        "    else:\n",
        "        return \"NOT FOUND\""
      ],
      "metadata": {
        "id": "nxhj8CTI8CLR"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Pydantic Models ===\n",
        "class EnzymeSubstratePair(BaseModel):\n",
        "    enzyme: str\n",
        "    substrate: str\n",
        "\n",
        "class RelationshipList(BaseModel):\n",
        "    reasoning: str\n",
        "    pairs: list[EnzymeSubstratePair]\n",
        "\n",
        "# === Prompt ===\n",
        "prompt_template1 = PromptTemplate.from_template(\"\"\"\n",
        "The following text is an excerpt from a scientific paper discussing enzymatic activity:\n",
        "\n",
        "{text}\n",
        "\n",
        "---\n",
        "\n",
        "### Task: Extract Enzyme–Substrate Relationships\n",
        "\n",
        "Analyze the text and perform these steps:\n",
        "\n",
        "1. Identify enzymes and their substrates, only if the action is clearly stated or implied (e.g., \"Enzyme A phosphorylates B\").\n",
        "2. Normalize enzyme and substrate names using gene symbols, protein names, or EC numbers where possible.\n",
        "3. Show your reasoning: briefly explain how you identified each pair (with supporting sentence).\n",
        "4. Return only a single valid JSON in this example format:\n",
        "\n",
        "{{\n",
        "  \"reasoning\": \"Step-by-step explanation here...\",\n",
        "  \"pairs\": [\n",
        "    {{\"enzyme\": \"PPM1D\", \"substrate\": \"RUNX2\"}},\n",
        "    {{\"enzyme\": \"CDK1\", \"substrate\": \"Histone H1\"}}\n",
        "  ]\n",
        "}}\n",
        "\"\"\")\n",
        "\n",
        "# === Function with Retry ===\n",
        "def extract_enzyme_substrate_pairs(llm, chain, prompt_template, full_text, retries=3, wait=2):\n",
        "    for attempt in range(1, retries + 1):\n",
        "        try:\n",
        "            result = chain.run(text=full_text)\n",
        "            return result\n",
        "        except Exception as e:\n",
        "            print(f\"[Attempt {attempt}] Failed: {e}\")\n",
        "            if attempt < retries:\n",
        "                time.sleep(wait)\n",
        "                wait *= 2\n",
        "            else:\n",
        "                raw_output = llm.invoke(prompt_template.format(text=full_text)).content\n",
        "                print(\"Final raw output:\\n\", raw_output)\n",
        "                raise RuntimeError(\"All retries failed.\")"
      ],
      "metadata": {
        "id": "ssnJRrON8X3T"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Pydantic Models ===\n",
        "# === New Pydantic Models ===\n",
        "class IndexPair(BaseModel):\n",
        "    enzyme: int\n",
        "    substrate: int\n",
        "\n",
        "class MatchSelection(BaseModel):\n",
        "    reasoning: str\n",
        "    pairs: IndexPair\n",
        "\n",
        "# === Prompt ===\n",
        "prompt_template2 = PromptTemplate.from_template(\"\"\"\n",
        "The following text is an excerpt from a scientific paper discussing enzymatic activity:\n",
        "\n",
        "{text}\n",
        "\n",
        "From this text, we have extracted the following enzyme–substrate relationship:\n",
        "\n",
        "{enzyme_name} – {substrate_name}\n",
        "\n",
        "We then searched UniProt (uniprot.org) and found several possible matches for both entities:\n",
        "\n",
        "**Enzyme search results**:\n",
        "{enzyme_uniprot_results}\n",
        "\n",
        "**Substrate search results**:\n",
        "{substrate_uniprot_results}\n",
        "\n",
        "---\n",
        "\n",
        "### Task: Select the Best-Matching UniProt Entries\n",
        "\n",
        "Analyze the relationship within the context of the original text and perform the following steps:\n",
        "\n",
        "1. Examine each UniProt search result for both the enzyme and the substrate.\n",
        "2. Consider organism (e.g., human preferred), gene/protein name relevance, functional description, and contextual fit.\n",
        "3. Show your reasoning: briefly explain how you selected each match, and which part of the original text supports your choice.\n",
        "4. Return a single valid JSON object in the following example format:\n",
        "\n",
        "{{\n",
        "  \"reasoning\": \"Step-by-step explanation here...\",\n",
        "  \"pairs\": {{\n",
        "    \"enzyme\": 0,\n",
        "    \"substrate\": 1\n",
        "  }}\n",
        "}}\n",
        "\"\"\")\n",
        "\n",
        "# === Function with Retry ===\n",
        "def match_best_uniprot_indices(\n",
        "    llm,\n",
        "    chain,\n",
        "    prompt_template,\n",
        "    full_text,\n",
        "    enzyme_name,\n",
        "    substrate_name,\n",
        "    enzyme_uniprot_results,\n",
        "    substrate_uniprot_results,\n",
        "    retries=3,\n",
        "    wait=2\n",
        "):\n",
        "    for attempt in range(1, retries + 1):\n",
        "        try:\n",
        "            result = chain.run(\n",
        "                text=full_text,\n",
        "                enzyme_name=enzyme_name,\n",
        "                substrate_name=substrate_name,\n",
        "                enzyme_uniprot_results=enzyme_uniprot_results,\n",
        "                substrate_uniprot_results=substrate_uniprot_results\n",
        "            )\n",
        "            return result\n",
        "        except Exception as e:\n",
        "            print(f\"[Attempt {attempt}] Failed: {e}\")\n",
        "            if attempt < retries:\n",
        "                time.sleep(wait)\n",
        "                wait *= 2\n",
        "            else:\n",
        "                # Fallback: dump raw LLM output to debug\n",
        "                raw_output = llm.invoke(\n",
        "                    prompt_template.format(\n",
        "                        text=full_text,\n",
        "                        enzyme_name=enzyme_name,\n",
        "                        substrate_name=substrate_name,\n",
        "                        enzyme_uniprot_results=enzyme_uniprot_results,\n",
        "                        substrate_uniprot_results=substrate_uniprot_results\n",
        "                    )\n",
        "                ).content\n",
        "                print(\"Final raw output:\\n\", raw_output)\n",
        "                raise RuntimeError(\"All retries failed.\")"
      ],
      "metadata": {
        "id": "kqolPlqpBIuj"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_query_type(identifier):\n",
        "    if re.match(r'^[OPQ][0-9][A-Z0-9]{3}[0-9]$', identifier) or re.match(r'^[A-NR-Z][0-9]{5}$', identifier):\n",
        "        return f'accession:{identifier}'  # UniProt Accession\n",
        "    elif re.match(r'^\\d+\\.\\d+\\.\\d+\\.\\d+$', identifier):\n",
        "        return f'ec:{identifier}'  # EC number\n",
        "    elif identifier.isupper() and len(identifier) <= 10:\n",
        "        return f'gene_exact:{identifier}'  # Gene symbol\n",
        "    else:\n",
        "        return identifier  # Free text or protein name\n",
        "\n",
        "def get_uniprot_details_from_accession(accession):\n",
        "    url = f\"https://rest.uniprot.org/uniprotkb/{accession}.json\"\n",
        "    response = requests.get(url)\n",
        "    if response.ok:\n",
        "        data = response.json()\n",
        "\n",
        "        # Protein name fallback logic\n",
        "        try:\n",
        "            protein_name = data[\"proteinDescription\"][\"recommendedName\"][\"fullName\"][\"value\"]\n",
        "        except KeyError:\n",
        "            try:\n",
        "                alt_names = data[\"proteinDescription\"].get(\"alternativeNames\", [])\n",
        "                protein_name = alt_names[0][\"fullName\"][\"value\"] if alt_names else \"Unknown\"\n",
        "            except Exception:\n",
        "                protein_name = \"Unknown\"\n",
        "\n",
        "        # Genes list, safely handle None\n",
        "        genes = [g.get('geneName', {}).get('value') for g in data.get(\"genes\", [])]\n",
        "        genes = [g for g in genes if g]  # filter None\n",
        "\n",
        "        return {\n",
        "            \"primary\": data.get(\"primaryAccession\"),\n",
        "            \"secondary\": data.get(\"secondaryAccessions\", []),\n",
        "            \"protein\": protein_name,\n",
        "            \"genes\": genes,\n",
        "            \"organism\": data.get(\"organism\", {}).get(\"scientificName\")\n",
        "        }\n",
        "    return None\n",
        "\n",
        "def query_uniprot_all(identifier, max_results=3):\n",
        "    query = detect_query_type(identifier)\n",
        "    url = \"https://rest.uniprot.org/uniprotkb/search\"\n",
        "    params = {\n",
        "        \"query\": query,\n",
        "        \"fields\": \"accession\",\n",
        "        \"format\": \"tsv\",\n",
        "        \"size\": max_results\n",
        "    }\n",
        "\n",
        "    response = requests.get(url, params=params)\n",
        "    if not response.ok or response.text.strip().count(\"\\n\") < 1:\n",
        "        print(f\"No UniProt entry found for '{identifier}'\")\n",
        "        raise Exception(f\"No UniProt entry found for '{identifier}'\")\n",
        "        # print(f\"No UniProt entry found for '{identifier}'\")\n",
        "        # return \"\", []\n",
        "\n",
        "    accessions = [line.split(\"\\t\")[0] for line in response.text.strip().split(\"\\n\")[1:]]\n",
        "\n",
        "    output_lines = []\n",
        "    details_list = []\n",
        "\n",
        "    for i, acc in enumerate(accessions):\n",
        "        header = f\"\\nsearch_result[{i}] for input: {identifier}\"\n",
        "        details = get_uniprot_details_from_accession(acc)\n",
        "\n",
        "        if details:\n",
        "            details_list.append(details)\n",
        "\n",
        "            block = (\n",
        "                f\"{header}\\n\"\n",
        "                f\"UniProt ID: {details['primary']}\\n\"\n",
        "                f\"Protein: {details['protein']}\\n\"\n",
        "                f\"Gene(s): {', '.join(details['genes']) if details['genes'] else 'N/A'}\\n\"\n",
        "                f\"Organism: {details['organism']}\\n\"\n",
        "                f\"Secondary Accessions: {', '.join(details['secondary']) if details['secondary'] else 'None'}\"\n",
        "            )\n",
        "        else:\n",
        "            block = f\"{header}\\nFailed to get details for accession: {acc}\"\n",
        "\n",
        "        output_lines.append(block)\n",
        "\n",
        "    return \"\\n\".join(output_lines), details_list\n"
      ],
      "metadata": {
        "id": "HiKlBdVn8uGn"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from flask import Flask, request, render_template_string\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# ================== 1. Read ngrok token and open tunnel ==================\n",
        "with open('ngrok_authtoken.txt', 'r') as f:\n",
        "    NGROK_AUTH_TOKEN = f.read().strip()\n",
        "\n",
        "ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "port = 5000\n",
        "public_url = ngrok.connect(port).public_url\n",
        "print(f\"Public URL: {public_url}\")\n",
        "\n",
        "# ================== 2. Initialize Flask app ==================\n",
        "app = Flask(__name__)\n",
        "app.secret_key = 'the_secret_key'\n",
        "\n",
        "# ================== 3. Import or define your actual project classes/functions ==================\n",
        "#   This snippet only serves as placeholders. In your real project, replace these\n",
        "#   placeholders with the actual imports/definitions from your code.\n",
        "# ------------------------------------------------------------------------------\n",
        "# from your_project import (\n",
        "#     ArticleRetriever,\n",
        "#     extract_abstract,\n",
        "#     RelationshipList,\n",
        "#     MatchSelection,\n",
        "#     query_uniprot_all,\n",
        "#     PydanticOutputParser,\n",
        "#     ChatGoogleGenerativeAI,\n",
        "#     OutputFixingParser,\n",
        "#     LLMChain,\n",
        "#     extract_enzyme_substrate_pairs,\n",
        "#     prompt_template1,\n",
        "#     prompt_template2,\n",
        "#     match_best_uniprot_indices\n",
        "# )\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "# ================== 4. Global variables ==================\n",
        "#     Store: abstract text, a combined list of reasoning+result (reason_result_list),\n",
        "#     and final lists for enzyme and substrate IDs\n",
        "abstract_text = \"\"\n",
        "reason_result_list = []  # Each element: {\"reasoning\": \"...\", \"result\": \"...\"}\n",
        "enzyme_list = []\n",
        "substrate_list = []\n",
        "\n",
        "# ================== 5. Three-column layout HTML template ==================\n",
        "HTML_TEMPLATE = r\"\"\"\n",
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "    <meta charset=\"utf-8\">\n",
        "    <title>Flask + pyngrok Demo</title>\n",
        "    <style>\n",
        "        /* Overall Page & Body */\n",
        "        body {\n",
        "            margin: 0;\n",
        "            padding: 0;\n",
        "            font-family: \"Segoe UI\", \"Roboto\", \"Helvetica Neue\", Arial, sans-serif;\n",
        "            background-color: #f0f2f5; /* Light background, akin to ChatGPT day mode */\n",
        "            color: #333;\n",
        "            height: 100vh; /* Ensures body fills screen height */\n",
        "        }\n",
        "\n",
        "        /* Container that holds the three columns */\n",
        "        .container {\n",
        "            display: flex;\n",
        "            flex-direction: row;\n",
        "            width: 100%;\n",
        "            height: 100%;\n",
        "            box-sizing: border-box;\n",
        "        }\n",
        "\n",
        "        /* Left, Middle, and Right Columns */\n",
        "        .left, .middle, .right {\n",
        "            padding: 20px;\n",
        "            overflow-y: auto;\n",
        "            box-sizing: border-box;\n",
        "            background-color: #fff; /* White background for contrast */\n",
        "        }\n",
        "        .left {\n",
        "            flex: 0 0 25%;\n",
        "            border-right: 1px solid #e0e0e0;\n",
        "        }\n",
        "        .middle {\n",
        "            flex: 1;\n",
        "            border-right: 1px solid #e0e0e0;\n",
        "        }\n",
        "        .right {\n",
        "            flex: 0 0 25%;\n",
        "        }\n",
        "\n",
        "        /* Headings in columns */\n",
        "        h3 {\n",
        "            margin: 0 0 10px 0;\n",
        "            font-size: 18px;\n",
        "            font-weight: bold;\n",
        "            color: #333;\n",
        "        }\n",
        "\n",
        "        /* Abstract box and Reasoning/Result boxes */\n",
        "        .abstract-box,\n",
        "        .reason-result-box {\n",
        "            margin-top: 5px;\n",
        "            padding: 15px;\n",
        "            background-color: #fff;\n",
        "            border: 1px solid #e0e0e0;\n",
        "            border-radius: 5px;\n",
        "            white-space: pre-wrap;\n",
        "        }\n",
        "\n",
        "        /* Smaller label-like headings for \"Reasoning\" and \"Result\" */\n",
        "        .title {\n",
        "            font-size: 14px;\n",
        "            font-weight: bold;\n",
        "            margin-bottom: 5px;\n",
        "            color: #555;\n",
        "        }\n",
        "\n",
        "        /* Horizontal line divider inside reason-result-box */\n",
        "        hr {\n",
        "            border: none;\n",
        "            border-top: 1px solid #eee;\n",
        "            margin: 5px 0;\n",
        "        }\n",
        "\n",
        "        /* Table for final enzyme/substrate info */\n",
        "        table {\n",
        "            border-collapse: collapse;\n",
        "            margin-top: 10px;\n",
        "            width: 100%;\n",
        "            background-color: #fff;\n",
        "        }\n",
        "        td, th {\n",
        "            border: 1px solid #e0e0e0;\n",
        "            padding: 8px;\n",
        "            text-align: left;\n",
        "            font-size: 14px;\n",
        "        }\n",
        "\n",
        "        /* Form elements */\n",
        "        form {\n",
        "            margin-top: 10px;\n",
        "        }\n",
        "        label {\n",
        "            font-size: 14px;\n",
        "            margin-bottom: 5px;\n",
        "            display: inline-block;\n",
        "        }\n",
        "        input[type=\"text\"] {\n",
        "            padding: 6px;\n",
        "            font-size: 14px;\n",
        "            margin-top: 5px;\n",
        "            box-sizing: border-box;\n",
        "            border: 1px solid #ccc;\n",
        "            border-radius: 4px;\n",
        "        }\n",
        "        button {\n",
        "            cursor: pointer;\n",
        "            padding: 8px 16px;\n",
        "            font-size: 14px;\n",
        "            border: none;\n",
        "            border-radius: 4px;\n",
        "            background-color: #4caf50;\n",
        "            color: #fff;\n",
        "        }\n",
        "        button:hover {\n",
        "            background-color: #43a047;\n",
        "        }\n",
        "    </style>\n",
        "</head>\n",
        "<body>\n",
        "<div class=\"container\">\n",
        "\n",
        "    <!-- Left Column: Enter PMID & retrieve abstract -->\n",
        "    <div class=\"left\">\n",
        "        <h3>Enter PMID</h3>\n",
        "        <form method=\"POST\">\n",
        "            <label for=\"pmid\">PMID:</label><br>\n",
        "            <input type=\"text\" id=\"pmid\" name=\"pmid\" style=\"width:80%;\" required\n",
        "            value=\"{{ current_pmid }}\">\n",
        "            <br><br>\n",
        "            <button type=\"submit\" name=\"action\" value=\"search\">Search Abstract</button>\n",
        "        </form>\n",
        "\n",
        "        {% if abstract_text %}\n",
        "        <div class=\"abstract-box\">\n",
        "            <strong>Abstract Retrieved:</strong><br>\n",
        "            {{ abstract_text }}\n",
        "        </div>\n",
        "        <form method=\"POST\">\n",
        "            <input type=\"hidden\" name=\"pmid\" value=\"{{ current_pmid }}\">\n",
        "            <button type=\"submit\" name=\"action\" value=\"extract\">Extract Information</button>\n",
        "        </form>\n",
        "        {% endif %}\n",
        "    </div>\n",
        "\n",
        "    <!-- Middle Column: Combined Reasoning + Result in one box -->\n",
        "    <div class=\"middle\">\n",
        "        <h3>Reasoning &amp; Results</h3>\n",
        "        {% for rr in reason_result_list %}\n",
        "        <div class=\"reason-result-box\">\n",
        "            <div class=\"title\">Reasoning:</div>\n",
        "            {{ rr.reasoning }}\n",
        "            <hr>\n",
        "            <div class=\"title\">Result:</div>\n",
        "            {{ rr.result }}\n",
        "        </div>\n",
        "        {% endfor %}\n",
        "    </div>\n",
        "\n",
        "    <!-- Right Column: Display final enzyme_list & substrate_list -->\n",
        "    <div class=\"right\">\n",
        "        <h3>Final Enzyme / Substrate Information</h3>\n",
        "        <table>\n",
        "            <tr>\n",
        "                <th>Enzyme</th>\n",
        "                <th>Substrate</th>\n",
        "            </tr>\n",
        "            {% for e, s in enz_sub_pairs %}\n",
        "            <tr>\n",
        "                <td>{{ e }}</td>\n",
        "                <td>{{ s }}</td>\n",
        "            </tr>\n",
        "            {% endfor %}\n",
        "        </table>\n",
        "    </div>\n",
        "\n",
        "</div>\n",
        "</body>\n",
        "</html>\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# ================== 6. Main route: Three-column website ==================\n",
        "@app.route(\"/\", methods=[\"GET\", \"POST\"])\n",
        "def index():\n",
        "    global abstract_text, reason_result_list, enzyme_list, substrate_list\n",
        "\n",
        "    current_pmid = \"\"\n",
        "\n",
        "    if request.method == 'POST':\n",
        "        action = request.form.get(\"action\", \"\")\n",
        "        pmid_input = request.form.get(\"pmid\", \"\").strip()\n",
        "        current_pmid = pmid_input  # Used for display if user re-renders the page\n",
        "\n",
        "        if action == \"search\":\n",
        "            # ========== 1) Retrieve and extract abstract by PMID ==========\n",
        "            #     Clear old reason/result data each time a new search is done\n",
        "            try:\n",
        "                retriever = ArticleRetriever()\n",
        "                res, html_content, code = retriever.request_article(pmid_input)\n",
        "                cleaned = extract_abstract(html_content)\n",
        "                abstract_text = cleaned\n",
        "\n",
        "                reason_result_list.clear()\n",
        "                enzyme_list.clear()\n",
        "                substrate_list.clear()\n",
        "\n",
        "            except Exception as e:\n",
        "                # If retrieval fails, show it in the abstract box\n",
        "                abstract_text = f\"Failed to retrieve abstract: {str(e)}\"\n",
        "\n",
        "        elif action == \"extract\" and abstract_text:\n",
        "            # ========== 2) Use the core backend code to extract/parse ==========\n",
        "            try:\n",
        "                # ---------------------------------------------------------\n",
        "                # (Below is the original code, but adapted to combine Reasoning/Result)\n",
        "                pmid = pmid_input\n",
        "\n",
        "                # Step 1: Retrieve & Abstract\n",
        "                retriever = ArticleRetriever()\n",
        "                res, html_content, code = retriever.request_article(pmid)\n",
        "                cleaned_text = extract_abstract(html_content)\n",
        "\n",
        "                # Show the abstract in Reasoning/Result as well\n",
        "                reason_result_list.append({\n",
        "                    \"reasoning\": \"Extracted the abstract from article\",\n",
        "                    \"result\": f\"Abstract:\\n{cleaned_text}\"\n",
        "                })\n",
        "\n",
        "                # Step 2: Set GOOGLE_API_KEY\n",
        "                os.environ[\"GOOGLE_API_KEY\"] = os.environ.get(\"GEMINI_15_API_KEY\", None)\n",
        "\n",
        "                parser1 = PydanticOutputParser(pydantic_object=RelationshipList)\n",
        "                llm = ChatGoogleGenerativeAI(model=\"models/gemini-1.5-pro-latest\", temperature=0)\n",
        "                output_parser1 = OutputFixingParser.from_llm(parser=parser1, llm=llm)\n",
        "                chain1 = LLMChain(llm=llm, prompt=prompt_template1, output_parser=output_parser1)\n",
        "\n",
        "                result1 = extract_enzyme_substrate_pairs(llm, chain1, prompt_template1, cleaned_text)\n",
        "\n",
        "                # Combine reasoning & result for the first extraction\n",
        "                pairs_str = \"\"\n",
        "                for pair in result1.pairs:\n",
        "                    pairs_str += f\"{pair.enzyme} acts on {pair.substrate}\\n\"\n",
        "                reason_result_list.append({\n",
        "                    \"reasoning\": result1.reasoning,\n",
        "                    \"result\": pairs_str\n",
        "                })\n",
        "\n",
        "                # Step 3: Initialize enzyme_list / substrate_list\n",
        "                enzyme_list = []\n",
        "                substrate_list = []\n",
        "\n",
        "                # For each pair, do UniProt searching, matching, etc.\n",
        "                for pair in result1.pairs:\n",
        "                    try:\n",
        "                        # Part A: Searching UniProt\n",
        "                        text_uniprot_enzyme = query_uniprot_all(pair.enzyme)\n",
        "                        text_uniprot_substr = query_uniprot_all(pair.substrate)\n",
        "                        reason_result_list.append({\n",
        "                            \"reasoning\": \"Searched UniProt (uniprot.org) for possible matches\",\n",
        "                            \"result\": f\"\"\"\\n**Enzyme search results**:\n",
        "    {text_uniprot_enzyme[0]}\n",
        "    \\n**Substrate search results**:\n",
        "    {text_uniprot_substr[0]}\"\"\"\n",
        "                        })\n",
        "\n",
        "                        # Part B: Matching best UniProt indices\n",
        "                        parser2 = PydanticOutputParser(pydantic_object=MatchSelection)\n",
        "                        output_parser2 = OutputFixingParser.from_llm(parser=parser2, llm=llm)\n",
        "                        chain2 = LLMChain(llm=llm, prompt=prompt_template2, output_parser=output_parser2)\n",
        "\n",
        "                        result2 = match_best_uniprot_indices(\n",
        "                            llm=llm,\n",
        "                            chain=chain2,\n",
        "                            prompt_template=prompt_template2,\n",
        "                            full_text=cleaned_text,\n",
        "                            enzyme_name=pair.enzyme,\n",
        "                            substrate_name=pair.substrate,\n",
        "                            enzyme_uniprot_results=text_uniprot_enzyme[0],\n",
        "                            substrate_uniprot_results=text_uniprot_substr[0]\n",
        "                        )\n",
        "                        reason_result_list.append({\n",
        "                            \"reasoning\": result2.reasoning,\n",
        "                            \"result\": f\"Use search_result[{result2.pairs.enzyme}] as the Enzyme and search_result[{result2.pairs.substrate}] as the Substrate.\"\n",
        "                        })\n",
        "\n",
        "                        # Finally, store the chosen IDs\n",
        "                        best_e_id = query_uniprot_all(pair.enzyme)[1][result2.pairs.enzyme]\n",
        "                        best_s_id = query_uniprot_all(pair.substrate)[1][result2.pairs.substrate]\n",
        "                        enzyme_list.append(best_e_id)\n",
        "                        substrate_list.append(best_s_id)\n",
        "                    except Exception as ex:\n",
        "                        pass\n",
        "\n",
        "                # Summarize final enzyme_list and substrate_list\n",
        "                reason_result_list.append({\n",
        "                    \"reasoning\": \"Collected final enzyme and substrate IDs\",\n",
        "                    \"result\": f\"Enzyme List: {enzyme_list}\\nSubstrate List: {substrate_list}\"\n",
        "                })\n",
        "                # ---------------------------------------------------------\n",
        "\n",
        "            except Exception as ex:\n",
        "                reason_result_list.append({\n",
        "                    \"reasoning\": \"Error occurred while extracting information\",\n",
        "                    \"result\": str(ex)\n",
        "                })\n",
        "\n",
        "    # Construct the right-column pairs of (enzyme_list, substrate_list)\n",
        "    enz_sub_pairs = list(zip(enzyme_list, substrate_list))\n",
        "\n",
        "    return render_template_string(\n",
        "        HTML_TEMPLATE,\n",
        "        abstract_text=abstract_text,\n",
        "        reason_result_list=reason_result_list,\n",
        "        enz_sub_pairs=enz_sub_pairs,\n",
        "        current_pmid=current_pmid\n",
        "    )\n",
        "\n",
        "# ================== 7. Entry point: Run the Flask app ==================\n",
        "if __name__ == \"__main__\":\n",
        "    app.run(port=port)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDXJ0eU9Pq09",
        "outputId": "56e299b3-61c4-4b71-c729-972f162ffc57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Public URL: https://dd2f-104-197-237-182.ngrok-free.app\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug:127.0.0.1 - - [23/Mar/2025 23:52:36] \"GET / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [23/Mar/2025 23:52:36] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "make get request to https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/29139553/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [23/Mar/2025 23:52:51] \"POST / HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "make get request to https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/29139553/\n",
            "No UniProt entry found for 'PP2A-AC'\n",
            "No UniProt entry found for 'PP2A-AC'\n",
            "No UniProt entry found for 'PP2A-AC'\n",
            "No UniProt entry found for 'IKKβ'\n",
            "No UniProt entry found for 'IκBα'\n",
            "[Attempt 1] Failed: Failed to parse MatchSelection from completion {\"reasoning\": \"The text explicitly states that PP2A regulates NF-\\u03baB signaling.  NF-\\u03baB is a key transcription factor in mammals, and the study strongly implies a mammalian context (no other organism is mentioned). Therefore, we prioritize human UniProt entries. \\n\\nFor the enzyme, while Q9Y570 (PPME1) is listed as a 'Protein phosphatase methylesterase 1', the text focuses on the PP2A complex itself, not an enzyme that acts *on* PP2A.  P01127 is 'Platelet-derived growth factor subunit B', completely unrelated.  Therefore, we lack a perfect match for the specific PP2A-AB\\u2032\\u2032\\u2032C complex within UniProt.  However, since the text focuses on the dephosphorylation activity of PP2A, we will not select an entry here and acknowledge this limitation.\\n\\nFor the substrate, RelA is mentioned as part of the NF-\\u03baB signaling pathway.  The human RelA protein (part of the NF-\\u03baB family) is a well-known participant in this pathway. The bacterial RelA proteins (O54408, Q54089, P9WHG9) are involved in the stringent response and are not related to NF-\\u03baB signaling.  Therefore, we select a human RelA protein as the most contextually appropriate substrate, even though it's not explicitly listed in the provided search results.  We will use index 1 as a placeholder, acknowledging that the actual UniProt ID needs to be retrieved separately.\", \"pairs\": {\"enzyme\": null, \"substrate\": null}}. Got: 2 validation errors for MatchSelection\n",
            "pairs.enzyme\n",
            "  Input should be a valid integer [type=int_type, input_value=None, input_type=NoneType]\n",
            "    For further information visit https://errors.pydantic.dev/2.10/v/int_type\n",
            "pairs.substrate\n",
            "  Input should be a valid integer [type=int_type, input_value=None, input_type=NoneType]\n",
            "    For further information visit https://errors.pydantic.dev/2.10/v/int_type\n",
            "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \n",
            "[Attempt 2] Failed: Failed to parse MatchSelection from completion {\"reasoning\": \"The passage mentions IKK\\u03b2 phosphorylating I\\u03baB\\u03b1, leading to its degradation and the release of RelA/p65.  It then states that PP2A *can* dephosphorylate RelA.  This suggests a potential interaction where PP2A acts as the enzyme and RelA/p65 acts as the substrate.  However, the provided list lacks a specific PP2A complex and the human RelA (Q04206).  Due to these limitations, no suitable pair can be formed from the provided options.\", \"pairs\": {\"enzyme\": null, \"substrate\": null}}. Got: 2 validation errors for MatchSelection\n",
            "pairs.enzyme\n",
            "  Input should be a valid integer [type=int_type, input_value=None, input_type=NoneType]\n",
            "    For further information visit https://errors.pydantic.dev/2.10/v/int_type\n",
            "pairs.substrate\n",
            "  Input should be a valid integer [type=int_type, input_value=None, input_type=NoneType]\n",
            "    For further information visit https://errors.pydantic.dev/2.10/v/int_type\n",
            "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \n",
            "[Attempt 3] Failed: Failed to parse MatchSelection from completion {\"reasoning\": \"The text explicitly states that PP2A regulates NF-\\u03baB signaling.  NF-\\u03baB is a key transcription factor in mammals, and the study strongly implies a mammalian context (no other organism is mentioned). Therefore, we prioritize human UniProt entries. \\n\\nFor the enzyme, while Q9Y570 (PPME1) is listed as a 'Protein phosphatase methylesterase 1', the text focuses on the PP2A complex itself, not an enzyme that acts *on* PP2A.  P01127 is 'Platelet-derived growth factor subunit B', completely unrelated.  Therefore, we lack a perfect match for the specific PP2A-AB\\u2032\\u2032\\u2032C complex within UniProt.  However, since the text focuses on the dephosphorylation activity of PP2A, we will not select an entry here and acknowledge this limitation.\\n\\nFor the substrate, RelA is mentioned as part of the NF-\\u03baB signaling pathway.  The human RelA protein (part of the NF-\\u03baB family) is a well-known participant in this pathway. The bacterial RelA proteins (O54408, Q54089, P9WHG9) are involved in the stringent response and are not related to NF-\\u03baB signaling.  Therefore, we select a human RelA protein as the most contextually appropriate substrate, even though it's not explicitly listed in the provided search results.  We will use index 1 as a placeholder, acknowledging that the actual UniProt ID needs to be retrieved separately.\", \"pairs\": {\"enzyme\": null, \"substrate\": null}}. Got: 2 validation errors for MatchSelection\n",
            "pairs.enzyme\n",
            "  Input should be a valid integer [type=int_type, input_value=None, input_type=NoneType]\n",
            "    For further information visit https://errors.pydantic.dev/2.10/v/int_type\n",
            "pairs.substrate\n",
            "  Input should be a valid integer [type=int_type, input_value=None, input_type=NoneType]\n",
            "    For further information visit https://errors.pydantic.dev/2.10/v/int_type\n",
            "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \n",
            "Final raw output:\n",
            " ```json\n",
            "{\n",
            "  \"reasoning\": \"The text discusses NF-κB signaling, a pathway found in mammals.  The experiment likely uses human cells, as no other organism is specified. Therefore, we prioritize human proteins. For the enzyme, 'Protein phosphatase methylesterase 1' (Q9Y570) is less likely to be directly involved in dephosphorylation compared to a PP2A complex involving a B′′′/striatin regulatory subunit. While the text doesn't explicitly name the specific striatin protein, it's implied.  For the substrate, 'RelA' refers to the NF-κB subunit, a key player in the described pathway. The human RelA (UniProt ID: Q04206, not in the provided list) is the most relevant. However, since it's not an option, we choose the closest homolog in a related organism, which is the Streptococcus dysgalactiae RelA (Q54089).  Although bacterial, it's still part of the Rel/NF-κB family and more likely to be relevant to the study's context than GTP pyrophosphokinase or the Mycobacterium tuberculosis RelA.\",\n",
            "  \"pairs\": {\n",
            "    \"enzyme\": 0,\n",
            "    \"substrate\": 1\n",
            "  }\n",
            "}\n",
            "```\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [23/Mar/2025 23:53:50] \"POST / HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No UniProt entry found for 'PP2A-ABC'\n",
            "make get request to https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/29139553/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [23/Mar/2025 23:54:04] \"POST / HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "make get request to https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/29139553/\n",
            "No UniProt entry found for 'PP2A-AC'\n",
            "No UniProt entry found for 'PP2A-AC'\n",
            "No UniProt entry found for 'PP2A-AC'\n",
            "No UniProt entry found for 'IKKβ'\n",
            "No UniProt entry found for 'IκBα'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [23/Mar/2025 23:54:31] \"POST / HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No UniProt entry found for 'PP2A-ABC'\n",
            "make get request to https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/22065775/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [23/Mar/2025 23:54:53] \"POST / HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "make get request to https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/22065775/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [23/Mar/2025 23:55:10] \"POST / HTTP/1.1\" 200 -\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pmid = \"22065775\"\n",
        "retriever = ArticleRetriever()\n",
        "res, html_content, code = retriever.request_article(pmid)\n",
        "cleaned_text = extract_abstract(html_content)\n",
        "print(cleaned_text)\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = os.environ.get(\"GEMINI_15_API_KEY\", None)\n",
        "\n",
        "parser1 = PydanticOutputParser(pydantic_object=RelationshipList)\n",
        "llm = ChatGoogleGenerativeAI(model=\"models/gemini-1.5-pro-latest\", temperature=0)\n",
        "output_parser1 = OutputFixingParser.from_llm(parser=parser1, llm=llm)\n",
        "\n",
        "chain1 = LLMChain(llm=llm, prompt=prompt_template1, output_parser=output_parser1)\n",
        "\n",
        "result1 = extract_enzyme_substrate_pairs(llm, chain1, prompt_template1, cleaned_text)\n",
        "\n",
        "print(\"Reasoning:\")\n",
        "print(result1.reasoning)\n",
        "print(\"Result:\")\n",
        "for pair in result1.pairs:\n",
        "    print(f\"{pair.enzyme} acts on {pair.substrate}\")\n",
        "\n",
        "\n",
        "\n",
        "enzyme_list = []\n",
        "substrate_list = []\n",
        "\n",
        "\n",
        "for pair in result1.pairs:\n",
        "    print(\"Reasoning:\")\n",
        "    print(f\"\"\"Searched UniProt (uniprot.org) and found several possible matches for both entities:\"\"\")\n",
        "    print(\"Result:\")\n",
        "    print(f\"\"\"**Enzyme search results**:\n",
        "{query_uniprot_all(pair.enzyme)[0]}\n",
        "**Substrate search results**:\n",
        "{query_uniprot_all(pair.substrate)[0]}\"\"\")\n",
        "\n",
        "    parser2 = PydanticOutputParser(pydantic_object=MatchSelection)\n",
        "    output_parser2 = OutputFixingParser.from_llm(parser=parser2, llm=llm)\n",
        "    chain2 = LLMChain(llm=llm, prompt=prompt_template2, output_parser=output_parser2)\n",
        "    result2 = match_best_uniprot_indices(\n",
        "        llm=llm,\n",
        "        chain=chain2,\n",
        "        prompt_template=prompt_template2,\n",
        "        full_text=cleaned_text,\n",
        "        enzyme_name=pair.enzyme,\n",
        "        substrate_name=pair.substrate,\n",
        "        enzyme_uniprot_results=query_uniprot_all(pair.enzyme)[0],\n",
        "        substrate_uniprot_results=query_uniprot_all(pair.substrate)[0]\n",
        "    )\n",
        "    print(\"Reasoning:\")\n",
        "    print(result2.reasoning)\n",
        "    print(\"Result:\")\n",
        "    print(result2.pairs)\n",
        "\n",
        "    enzyme_list.append(query_uniprot_all(pair.enzyme)[1][result2.pairs.enzyme])\n",
        "    substrate_list.append(query_uniprot_all(pair.substrate)[1][result2.pairs.substrate])\n",
        "\n",
        "\n",
        "\n",
        "print(enzyme_list)\n",
        "print(substrate_list)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXxLLtANlozA",
        "outputId": "2d01e302-3820-4ecb-baeb-69c685df09ee"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "make get request to https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/22065775/\n",
            "The inactivation of the p53 tumor suppressor pathway in many cancers often increases their resistance to anticancer therapy. Here we show that a previously proposed strategy directed to Wip1 inhibition could be ineffective in tumors lacking p53. On the contrary, Wip1 overexpression sensitized these tumors to chemotherapeutic agents. This effect was mediated through interaction between Wip1 and RUNX2 that resulted, in response to anticancer treatment, in RUNX2-dependent transcriptional induction of the proapoptotic Bax protein. The potentiating effects of Wip1 overexpression on chemotherapeutic agents were directed only to tumor cells lacking p53. The overexpression of Wip1 in normal tissues provided protection from cisplatin-induced apoptosis through decreased strength of upstream signaling to p53. Thus, Wip1 phosphatase promotes apoptosis in p53-negative tumors and protects normal tissues during treatment with anticancer agents.\n",
            "Keywords: caspases, Bcl-2 family, dephosphorylation, intestine\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-9cf52ded33a5>:13: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
            "  chain1 = LLMChain(llm=llm, prompt=prompt_template1, output_parser=output_parser1)\n",
            "<ipython-input-13-61be79fde537>:40: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  result = chain.run(text=full_text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reasoning:\n",
            "1. **PPM1D (Wip1) and RUNX2:** The text states 'This effect was mediated through interaction between Wip1 and RUNX2 that resulted... in RUNX2-dependent transcriptional induction of the proapoptotic Bax protein.'  This implies an interaction where Wip1 acts upon RUNX2, likely through dephosphorylation (given Wip1 is a phosphatase and the keywords include 'dephosphorylation').\n",
            "2. **PPM1D (Wip1) and p53:** The text mentions 'The overexpression of Wip1 in normal tissues provided protection from cisplatin-induced apoptosis through decreased strength of upstream signaling to p53.' This suggests Wip1 acts on an upstream component of the p53 pathway, ultimately affecting p53 activity.  However, the specific substrate in the p53 pathway is not explicitly mentioned, only the downstream effect on p53 signaling. Therefore, we can infer Wip1's action relates to p53 regulation but cannot definitively identify a direct substrate within the p53 pathway based on this text.\n",
            "Result:\n",
            "PPM1D acts on RUNX2\n",
            "Reasoning:\n",
            "Searched UniProt (uniprot.org) and found several possible matches for both entities:\n",
            "Result:\n",
            "**Enzyme search results**:\n",
            "\n",
            "search_result[0] for input: PPM1D\n",
            "UniProt ID: O15297\n",
            "Protein: Protein phosphatase 1D\n",
            "Gene(s): PPM1D\n",
            "Organism: Homo sapiens\n",
            "Secondary Accessions: Q53XP4, Q6P991, Q8IVR6\n",
            "\n",
            "search_result[1] for input: PPM1D\n",
            "UniProt ID: Q9QZ67\n",
            "Protein: Protein phosphatase 1D\n",
            "Gene(s): Ppm1d\n",
            "Organism: Mus musculus\n",
            "Secondary Accessions: B1B0B0\n",
            "\n",
            "search_result[2] for input: PPM1D\n",
            "UniProt ID: F7FER9\n",
            "Protein: Unknown\n",
            "Gene(s): Ppm1d\n",
            "Organism: Rattus norvegicus\n",
            "Secondary Accessions: None\n",
            "**Substrate search results**:\n",
            "\n",
            "search_result[0] for input: RUNX2\n",
            "UniProt ID: Q13950\n",
            "Protein: Runt-related transcription factor 2\n",
            "Gene(s): RUNX2\n",
            "Organism: Homo sapiens\n",
            "Secondary Accessions: O14614, O14615, O95181\n",
            "\n",
            "search_result[1] for input: RUNX2\n",
            "UniProt ID: Q9Z2J9\n",
            "Protein: Runt-related transcription factor 2\n",
            "Gene(s): Runx2\n",
            "Organism: Rattus norvegicus\n",
            "Secondary Accessions: Q99NC7\n",
            "\n",
            "search_result[2] for input: RUNX2\n",
            "UniProt ID: Q08775\n",
            "Protein: Runt-related transcription factor 2\n",
            "Gene(s): Runx2\n",
            "Organism: Mus musculus\n",
            "Secondary Accessions: O35183, Q08776, Q9JLN0, Q9QUQ6, Q9QY29, Q9R0U4, Q9Z2J7\n",
            "Reasoning:\n",
            "The text discusses the effect of Wip1 (PPM1D) on tumor cells and normal tissues, strongly implying a human context.  The text mentions the interaction between Wip1 and RUNX2 leading to Bax induction.  Therefore, we prioritize human entries for both enzyme and substrate.  For the enzyme PPM1D, `search_result[0]` (O15297) is the best match as it's a human protein with the correct name 'Protein phosphatase 1D'.  For the substrate RUNX2, `search_result[0]` (Q13950) is the best match as it's also a human protein with the correct name 'Runt-related transcription factor 2'.\n",
            "Result:\n",
            "enzyme=0 substrate=0\n",
            "[{'primary': 'O15297', 'secondary': ['Q53XP4', 'Q6P991', 'Q8IVR6'], 'protein': 'Protein phosphatase 1D', 'genes': ['PPM1D'], 'organism': 'Homo sapiens'}]\n",
            "[{'primary': 'Q13950', 'secondary': ['O14614', 'O14615', 'O95181'], 'protein': 'Runt-related transcription factor 2', 'genes': ['RUNX2'], 'organism': 'Homo sapiens'}]\n"
          ]
        }
      ]
    }
  ]
}