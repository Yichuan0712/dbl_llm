{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Environment Setup\n",
        "#### I use Google Colab to run this demonstration; if you're using a different environment, the setup process may vary. - Yichuan"
      ],
      "metadata": {
        "id": "BjwKg-DbH5Gz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CpoGj0xbEkfP"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "if not os.path.ismount('/content/drive'):\n",
        "    drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/drive/MyDrive/.ssh/ ~/\n",
        "!ls ~/.ssh/ -a\n",
        "!ssh -T git@github.com\n",
        "!git clone git@github.com:Yichuan0712/dbl_llm.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JmUL2ypsE0Ra",
        "outputId": "e9815823-2b78-4287-f6cc-dbde02dae100"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".  ..  github_id_rsa  hellbender_id_rsa  id_rsa  id_rsa.pub  known_hosts\n",
            "Hi Yichuan0712! You've successfully authenticated, but GitHub does not provide shell access.\n",
            "Cloning into 'dbl_llm'...\n",
            "remote: Enumerating objects: 67, done.\u001b[K\n",
            "remote: Counting objects: 100% (67/67), done.\u001b[K\n",
            "remote: Compressing objects: 100% (54/54), done.\u001b[K\n",
            "remote: Total 67 (delta 17), reused 61 (delta 11), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (67/67), 2.95 MiB | 2.65 MiB/s, done.\n",
            "Resolving deltas: 100% (17/17), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/OSU/yichuan_gemini.env /content/.env  # Get your own gemini key\n",
        "!cp /content/drive/MyDrive/OSU/ngrok_authtoken.txt /content/dbl_llm/ngrok_authtoken.txt # To run the graphical interface on Colab, you’ll also need to set up an ngrok key."
      ],
      "metadata": {
        "id": "vRpECz0nkCyW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok -q\n",
        "!pip install python-dotenv -q\n",
        "!pip install fake_useragent -q\n",
        "!pip install shortuuid -q\n",
        "!pip install ratelimit -q\n",
        "!pip install langchain-openai -q\n",
        "!pip install -U langchain-google-genai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XZmlNGjzHCyB",
        "outputId": "d1f10bce-4dbb-46e8-f7ce-5cb4db65c048"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/125.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m122.9/125.8 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.8/125.8 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for ratelimit (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.1/60.1 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m420.1/420.1 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-2.1.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from langchain-google-genai)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting google-ai-generativelanguage<0.7.0,>=0.6.16 (from langchain-google-genai)\n",
            "  Downloading google_ai_generativelanguage-0.6.17-py3-none-any.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.47 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai) (0.3.49)\n",
            "Requirement already satisfied: pydantic<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai) (2.10.6)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (2.24.2)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (5.29.4)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.47->langchain-google-genai) (0.3.18)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.47->langchain-google-genai) (9.0.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.47->langchain-google-genai) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.47->langchain-google-genai) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.47->langchain-google-genai) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.47->langchain-google-genai) (4.12.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain-google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain-google-genai) (2.27.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (1.69.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (2.32.3)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (1.71.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (1.71.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (4.9)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.47->langchain-google-genai) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.47->langchain-google-genai) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.47->langchain-google-genai) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.47->langchain-google-genai) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.47->langchain-google-genai) (0.23.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.47->langchain-google-genai) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.47->langchain-google-genai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.47->langchain-google-genai) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.47->langchain-google-genai) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.47->langchain-google-genai) (0.14.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (2.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.47->langchain-google-genai) (1.3.1)\n",
            "Downloading langchain_google_genai-2.1.1-py3-none-any.whl (40 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading google_ai_generativelanguage-0.6.17-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: filetype, google-ai-generativelanguage, langchain-google-genai\n",
            "  Attempting uninstall: google-ai-generativelanguage\n",
            "    Found existing installation: google-ai-generativelanguage 0.6.15\n",
            "    Uninstalling google-ai-generativelanguage-0.6.15:\n",
            "      Successfully uninstalled google-ai-generativelanguage-0.6.15\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-generativeai 0.8.4 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.17 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed filetype-1.2.0 google-ai-generativelanguage-0.6.17 langchain-google-genai-2.1.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "73e3bb4af3d94aa089e67977db0046d3"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv\n",
        "load_dotenv()"
      ],
      "metadata": {
        "id": "c8vRij6OkHkJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e995689-0b4c-4171-9a9d-292f9498d985"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/dbl_llm')"
      ],
      "metadata": {
        "id": "nMu9qgHqG90s"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function Definitions"
      ],
      "metadata": {
        "id": "yidezBOSJSZZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from extractor.article_retriever import ArticleRetriever\n",
        "from extractor.html_table_extractor import HtmlTableExtractor\n",
        "import os\n",
        "import time\n",
        "import re\n",
        "import requests\n",
        "from pydantic import BaseModel\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.output_parsers import OutputFixingParser, PydanticOutputParser\n",
        "from langchain.chains import LLMChain\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from bs4 import BeautifulSoup"
      ],
      "metadata": {
        "id": "RhUf6HmvKoO9"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_abstract(html):\n",
        "    soup = BeautifulSoup(html, 'html.parser')\n",
        "\n",
        "    article_section = soup.find('section', {'class': 'abstract'})\n",
        "\n",
        "    if article_section:\n",
        "        return '\\n'.join([p.get_text() for p in article_section.find_all('p')])\n",
        "    else:\n",
        "        return \"NOT FOUND\""
      ],
      "metadata": {
        "id": "nxhj8CTI8CLR"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Output Schema\n",
        "class EnzymeSubstratePair(BaseModel):\n",
        "    enzyme: str\n",
        "    substrate: str\n",
        "\n",
        "class RelationshipList(BaseModel):\n",
        "    reasoning: str\n",
        "    pairs: list[EnzymeSubstratePair]\n",
        "\n",
        "# Prompt\n",
        "prompt_extract_enzyme_substrate_pairs = PromptTemplate.from_template(\"\"\"\n",
        "The following text is an excerpt from a scientific paper discussing enzymatic activity:\n",
        "\n",
        "{text}\n",
        "\n",
        "---\n",
        "\n",
        "### Task: Extract Enzyme–Substrate Relationships\n",
        "\n",
        "Analyze the text and perform these steps:\n",
        "\n",
        "1. Identify enzymes and their substrates, only if the action is clearly stated or implied (e.g., \"Enzyme A phosphorylates B\").\n",
        "2. Normalize enzyme and substrate names using gene symbols, protein names, or EC numbers where possible.\n",
        "3. Show your reasoning: briefly explain how you identified each pair (with supporting sentence).\n",
        "4. Return only a single valid JSON in this example format:\n",
        "\n",
        "{{\n",
        "  \"reasoning\": \"Step-by-step explanation here...\",\n",
        "  \"pairs\": [\n",
        "    {{\"enzyme\": \"PPM1D\", \"substrate\": \"RUNX2\"}},\n",
        "    {{\"enzyme\": \"CDK1\", \"substrate\": \"Histone H1\"}}\n",
        "  ]\n",
        "}}\n",
        "\"\"\")\n",
        "\n",
        "# Function with Retry\n",
        "def extract_enzyme_substrate_pairs(llm, chain, prompt_template, full_text, retries=3, wait=2):\n",
        "    for attempt in range(1, retries + 1):\n",
        "        try:\n",
        "            result = chain.run(text=full_text)\n",
        "            return result\n",
        "        except Exception as e:\n",
        "            print(f\"[Attempt {attempt}] Failed: {e}\")\n",
        "            if attempt < retries:\n",
        "                time.sleep(wait)\n",
        "                wait *= 2\n",
        "            else:\n",
        "                raw_output = llm.invoke(prompt_template.format(text=full_text)).content\n",
        "                print(\"Final raw output:\\n\", raw_output)\n",
        "                raise RuntimeError(\"All retries failed.\")"
      ],
      "metadata": {
        "id": "ssnJRrON8X3T"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Output Schema\n",
        "class IndexPair(BaseModel):\n",
        "    enzyme: int\n",
        "    substrate: int\n",
        "\n",
        "class MatchSelection(BaseModel):\n",
        "    reasoning: str\n",
        "    pairs: IndexPair\n",
        "\n",
        "# Prompt\n",
        "prompt_match_best_uniprot_indices = PromptTemplate.from_template(\"\"\"\n",
        "The following text is an excerpt from a scientific paper discussing enzymatic activity:\n",
        "\n",
        "{text}\n",
        "\n",
        "From this text, we have extracted the following enzyme–substrate relationship:\n",
        "\n",
        "{enzyme_name} – {substrate_name}\n",
        "\n",
        "We then searched UniProt (uniprot.org) and found several possible matches for both entities:\n",
        "\n",
        "**Enzyme search results**:\n",
        "{enzyme_uniprot_results}\n",
        "\n",
        "**Substrate search results**:\n",
        "{substrate_uniprot_results}\n",
        "\n",
        "---\n",
        "\n",
        "### Task: Select the Best-Matching UniProt Entries\n",
        "\n",
        "Analyze the relationship within the context of the original text and perform the following steps:\n",
        "\n",
        "1. Examine each UniProt search result for both the enzyme and the substrate.\n",
        "2. Consider organism (e.g., human preferred), gene/protein name relevance, functional description, and contextual fit.\n",
        "3. Show your reasoning: briefly explain how you selected each match, and which part of the original text supports your choice.\n",
        "4. Return a single valid JSON object in the following example format:\n",
        "\n",
        "{{\n",
        "  \"reasoning\": \"Step-by-step explanation here...\",\n",
        "  \"pairs\": {{\n",
        "    \"enzyme\": 0,\n",
        "    \"substrate\": 1\n",
        "  }}\n",
        "}}\n",
        "\"\"\")\n",
        "\n",
        "# Function with Retry\n",
        "def match_best_uniprot_indices(\n",
        "    llm,\n",
        "    chain,\n",
        "    prompt_template,\n",
        "    full_text,\n",
        "    enzyme_name,\n",
        "    substrate_name,\n",
        "    enzyme_uniprot_results,\n",
        "    substrate_uniprot_results,\n",
        "    retries=3,\n",
        "    wait=2\n",
        "):\n",
        "    for attempt in range(1, retries + 1):\n",
        "        try:\n",
        "            result = chain.run(\n",
        "                text=full_text,\n",
        "                enzyme_name=enzyme_name,\n",
        "                substrate_name=substrate_name,\n",
        "                enzyme_uniprot_results=enzyme_uniprot_results,\n",
        "                substrate_uniprot_results=substrate_uniprot_results\n",
        "            )\n",
        "            return result\n",
        "        except Exception as e:\n",
        "            print(f\"[Attempt {attempt}] Failed: {e}\")\n",
        "            if attempt < retries:\n",
        "                time.sleep(wait)\n",
        "                wait *= 2\n",
        "            else:\n",
        "                # Fallback: dump raw LLM output to debug\n",
        "                raw_output = llm.invoke(\n",
        "                    prompt_template.format(\n",
        "                        text=full_text,\n",
        "                        enzyme_name=enzyme_name,\n",
        "                        substrate_name=substrate_name,\n",
        "                        enzyme_uniprot_results=enzyme_uniprot_results,\n",
        "                        substrate_uniprot_results=substrate_uniprot_results\n",
        "                    )\n",
        "                ).content\n",
        "                print(\"Final raw output:\\n\", raw_output)\n",
        "                raise RuntimeError(\"All retries failed.\")"
      ],
      "metadata": {
        "id": "kqolPlqpBIuj"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_query_type(identifier):\n",
        "    if re.match(r'^[OPQ][0-9][A-Z0-9]{3}[0-9]$', identifier) or re.match(r'^[A-NR-Z][0-9]{5}$', identifier):\n",
        "        return f'accession:{identifier}'  # UniProt Accession\n",
        "    elif re.match(r'^\\d+\\.\\d+\\.\\d+\\.\\d+$', identifier):\n",
        "        return f'ec:{identifier}'  # EC number\n",
        "    elif identifier.isupper() and len(identifier) <= 10:\n",
        "        return f'gene_exact:{identifier}'  # Gene symbol\n",
        "    else:\n",
        "        return identifier  # Free text or protein name\n",
        "\n",
        "def get_uniprot_details_from_accession(accession):\n",
        "    url = f\"https://rest.uniprot.org/uniprotkb/{accession}.json\"\n",
        "    response = requests.get(url)\n",
        "    if response.ok:\n",
        "        data = response.json()\n",
        "\n",
        "        # Protein name fallback logic\n",
        "        try:\n",
        "            protein_name = data[\"proteinDescription\"][\"recommendedName\"][\"fullName\"][\"value\"]\n",
        "        except KeyError:\n",
        "            try:\n",
        "                alt_names = data[\"proteinDescription\"].get(\"alternativeNames\", [])\n",
        "                protein_name = alt_names[0][\"fullName\"][\"value\"] if alt_names else \"Unknown\"\n",
        "            except Exception:\n",
        "                protein_name = \"Unknown\"\n",
        "\n",
        "        # Genes list, safely handle None\n",
        "        genes = [g.get('geneName', {}).get('value') for g in data.get(\"genes\", [])]\n",
        "        genes = [g for g in genes if g]  # filter None\n",
        "\n",
        "        return {\n",
        "            \"primary\": data.get(\"primaryAccession\"),\n",
        "            \"secondary\": data.get(\"secondaryAccessions\", []),\n",
        "            \"protein\": protein_name,\n",
        "            \"genes\": genes,\n",
        "            \"organism\": data.get(\"organism\", {}).get(\"scientificName\")\n",
        "        }\n",
        "    return None\n",
        "\n",
        "def query_uniprot_all(identifier, max_results=3):\n",
        "    query = detect_query_type(identifier)\n",
        "    url = \"https://rest.uniprot.org/uniprotkb/search\"\n",
        "    params = {\n",
        "        \"query\": query,\n",
        "        \"fields\": \"accession\",\n",
        "        \"format\": \"tsv\",\n",
        "        \"size\": max_results\n",
        "    }\n",
        "\n",
        "    response = requests.get(url, params=params)\n",
        "    if not response.ok or response.text.strip().count(\"\\n\") < 1:\n",
        "        print(f\"No UniProt entry found for '{identifier}'\")\n",
        "        raise Exception(f\"No UniProt entry found for '{identifier}'\")\n",
        "        # print(f\"No UniProt entry found for '{identifier}'\")\n",
        "        # return \"\", []\n",
        "\n",
        "    accessions = [line.split(\"\\t\")[0] for line in response.text.strip().split(\"\\n\")[1:]]\n",
        "\n",
        "    output_lines = []\n",
        "    details_list = []\n",
        "\n",
        "    for i, acc in enumerate(accessions):\n",
        "        header = f\"\\nsearch_result[{i}] for input: {identifier}\"\n",
        "        details = get_uniprot_details_from_accession(acc)\n",
        "\n",
        "        if details:\n",
        "            details_list.append(details)\n",
        "\n",
        "            block = (\n",
        "                f\"{header}\\n\"\n",
        "                f\"UniProt ID: {details['primary']}\\n\"\n",
        "                f\"Protein: {details['protein']}\\n\"\n",
        "                f\"Gene(s): {', '.join(details['genes']) if details['genes'] else 'N/A'}\\n\"\n",
        "                f\"Organism: {details['organism']}\\n\"\n",
        "                f\"Secondary Accessions: {', '.join(details['secondary']) if details['secondary'] else 'None'}\"\n",
        "            )\n",
        "        else:\n",
        "            block = f\"{header}\\nFailed to get details for accession: {acc}\"\n",
        "\n",
        "        output_lines.append(block)\n",
        "\n",
        "    return \"\\n\".join(output_lines), details_list\n"
      ],
      "metadata": {
        "id": "HiKlBdVn8uGn"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run with Scripts"
      ],
      "metadata": {
        "id": "gYoikGarS-fj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pmid = \"22065775\"\n",
        "retriever = ArticleRetriever()\n",
        "res, html_content, code = retriever.request_article(pmid)\n",
        "\n",
        "cleaned_text = extract_abstract(html_content)\n",
        "print(\"\\033[32mAbstract:\\033[0m\")\n",
        "print(cleaned_text)\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = os.environ.get(\"GEMINI_15_API_KEY\", None)\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model=\"models/gemini-1.5-pro-latest\", temperature=0)\n",
        "\n",
        "parser_extract_enzyme_substrate_pairs = PydanticOutputParser(pydantic_object=RelationshipList)\n",
        "\n",
        "output_parser_extract_enzyme_substrate_pairs = OutputFixingParser.from_llm(parser=parser_extract_enzyme_substrate_pairs, llm=llm)\n",
        "\n",
        "chain_extract_enzyme_substrate_pairs = LLMChain(llm=llm, prompt=prompt_extract_enzyme_substrate_pairs, output_parser=output_parser_extract_enzyme_substrate_pairs)\n",
        "\n",
        "result_extract_enzyme_substrate_pairs = extract_enzyme_substrate_pairs(llm, chain_extract_enzyme_substrate_pairs, prompt_extract_enzyme_substrate_pairs, cleaned_text)\n",
        "\n",
        "print(\"\\n\\033[32mReasoning:\\033[0m\")\n",
        "print(result_extract_enzyme_substrate_pairs.reasoning)\n",
        "print(\"\\033[32mResult:\\033[0m\")\n",
        "for pair in result_extract_enzyme_substrate_pairs.pairs:\n",
        "    print(f\"{pair.enzyme} acts on {pair.substrate}\")\n",
        "\n",
        "\n",
        "enzyme_list = []\n",
        "substrate_list = []\n",
        "\n",
        "\n",
        "for pair in result_extract_enzyme_substrate_pairs.pairs:\n",
        "    print(\"\\n\\033[32mReasoning:\\033[0m\")\n",
        "    print(f\"\"\"Searched UniProt (uniprot.org) and found several possible matches for both entities:\"\"\")\n",
        "    print(\"\\033[32mResult:\\033[0m\")\n",
        "    print(f\"\"\"\\n\\033[33mEnzyme search results\\033[0m:\n",
        "{query_uniprot_all(pair.enzyme)[0]}\n",
        "\\n\\033[33mSubstrate search results\\033[0m:\n",
        "{query_uniprot_all(pair.substrate)[0]}\"\"\")\n",
        "\n",
        "    parser_match_best_uniprot_indice = PydanticOutputParser(pydantic_object=MatchSelection)\n",
        "    output_parser_match_best_uniprot_indice = OutputFixingParser.from_llm(parser=parser_match_best_uniprot_indice, llm=llm)\n",
        "    chain_match_best_uniprot_indice = LLMChain(llm=llm, prompt=prompt_match_best_uniprot_indices, output_parser=output_parser_match_best_uniprot_indice)\n",
        "    result_match_best_uniprot_indice = match_best_uniprot_indices(\n",
        "        llm=llm,\n",
        "        chain=chain_match_best_uniprot_indice,\n",
        "        prompt_template=prompt_match_best_uniprot_indices,\n",
        "        full_text=cleaned_text,\n",
        "        enzyme_name=pair.enzyme,\n",
        "        substrate_name=pair.substrate,\n",
        "        enzyme_uniprot_results=query_uniprot_all(pair.enzyme)[0],\n",
        "        substrate_uniprot_results=query_uniprot_all(pair.substrate)[0]\n",
        "    )\n",
        "    print(\"\\n\\033[32mReasoning:\\033[0m\")\n",
        "    print(result_match_best_uniprot_indice.reasoning)\n",
        "    print(\"\\033[32mResult:\\033[0m\")\n",
        "    print(result_match_best_uniprot_indice.pairs)\n",
        "\n",
        "    enzyme_list.append(query_uniprot_all(pair.enzyme)[1][result_match_best_uniprot_indice.pairs.enzyme])\n",
        "    substrate_list.append(query_uniprot_all(pair.substrate)[1][result_match_best_uniprot_indice.pairs.substrate])\n",
        "\n",
        "    print(enzyme_list[-1])\n",
        "    print(substrate_list[-1])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXxLLtANlozA",
        "outputId": "3a4220ff-bf23-43eb-f64d-c95dd1895bc9"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "make get request to https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/22065775/\n",
            "\u001b[32mAbstract:\u001b[0m\n",
            "The inactivation of the p53 tumor suppressor pathway in many cancers often increases their resistance to anticancer therapy. Here we show that a previously proposed strategy directed to Wip1 inhibition could be ineffective in tumors lacking p53. On the contrary, Wip1 overexpression sensitized these tumors to chemotherapeutic agents. This effect was mediated through interaction between Wip1 and RUNX2 that resulted, in response to anticancer treatment, in RUNX2-dependent transcriptional induction of the proapoptotic Bax protein. The potentiating effects of Wip1 overexpression on chemotherapeutic agents were directed only to tumor cells lacking p53. The overexpression of Wip1 in normal tissues provided protection from cisplatin-induced apoptosis through decreased strength of upstream signaling to p53. Thus, Wip1 phosphatase promotes apoptosis in p53-negative tumors and protects normal tissues during treatment with anticancer agents.\n",
            "Keywords: caspases, Bcl-2 family, dephosphorylation, intestine\n",
            "\n",
            "\u001b[32mReasoning:\u001b[0m\n",
            "The text states that 'Wip1 phosphatase promotes apoptosis in p53-negative tumors...'.  This implies Wip1 acts as a phosphatase, removing a phosphate group from a substrate.  Later, it mentions 'interaction between Wip1 and RUNX2 that resulted... in RUNX2-dependent transcriptional induction of Bax'. This suggests Wip1's action on RUNX2 affects its activity, implying RUNX2 is a substrate of Wip1. Wip1 is also known as PPM1D. The text also states 'The overexpression of Wip1 in normal tissues provided protection from cisplatin-induced apoptosis through decreased strength of upstream signaling to p53.' This implies Wip1 acts on an upstream component of the p53 pathway, dephosphorylating it and reducing p53 activation. However, the specific substrate in this pathway is not named.\n",
            "\u001b[32mResult:\u001b[0m\n",
            "PPM1D acts on RUNX2\n",
            "\n",
            "\u001b[32mReasoning:\u001b[0m\n",
            "Searched UniProt (uniprot.org) and found several possible matches for both entities:\n",
            "\u001b[32mResult:\u001b[0m\n",
            "\n",
            "\u001b[33mEnzyme search results\u001b[0m:\n",
            "\n",
            "search_result[0] for input: PPM1D\n",
            "UniProt ID: O15297\n",
            "Protein: Protein phosphatase 1D\n",
            "Gene(s): PPM1D\n",
            "Organism: Homo sapiens\n",
            "Secondary Accessions: Q53XP4, Q6P991, Q8IVR6\n",
            "\n",
            "search_result[1] for input: PPM1D\n",
            "UniProt ID: Q9QZ67\n",
            "Protein: Protein phosphatase 1D\n",
            "Gene(s): Ppm1d\n",
            "Organism: Mus musculus\n",
            "Secondary Accessions: B1B0B0\n",
            "\n",
            "search_result[2] for input: PPM1D\n",
            "UniProt ID: F7FER9\n",
            "Protein: Unknown\n",
            "Gene(s): Ppm1d\n",
            "Organism: Rattus norvegicus\n",
            "Secondary Accessions: None\n",
            "\n",
            "\u001b[33mSubstrate search results\u001b[0m:\n",
            "\n",
            "search_result[0] for input: RUNX2\n",
            "UniProt ID: Q13950\n",
            "Protein: Runt-related transcription factor 2\n",
            "Gene(s): RUNX2\n",
            "Organism: Homo sapiens\n",
            "Secondary Accessions: O14614, O14615, O95181\n",
            "\n",
            "search_result[1] for input: RUNX2\n",
            "UniProt ID: Q9Z2J9\n",
            "Protein: Runt-related transcription factor 2\n",
            "Gene(s): Runx2\n",
            "Organism: Rattus norvegicus\n",
            "Secondary Accessions: Q99NC7\n",
            "\n",
            "search_result[2] for input: RUNX2\n",
            "UniProt ID: Q08775\n",
            "Protein: Runt-related transcription factor 2\n",
            "Gene(s): Runx2\n",
            "Organism: Mus musculus\n",
            "Secondary Accessions: O35183, Q08776, Q9JLN0, Q9QUQ6, Q9QY29, Q9R0U4, Q9Z2J7\n",
            "\n",
            "\u001b[32mReasoning:\u001b[0m\n",
            "The text focuses on the effect of Wip1 (PPM1D) on tumor response to chemotherapy, a context heavily implying human cancer research.  The text mentions p53, a well-known human tumor suppressor.  Therefore, we prioritize human proteins.  For the enzyme PPM1D, search_result[0] (O15297) corresponds to the human protein. For the substrate RUNX2, search_result[0] (Q13950) is also the human protein.  The text explicitly states \"interaction between Wip1 and RUNX2\", further supporting the selection of the human versions of both proteins.\n",
            "\u001b[32mResult:\u001b[0m\n",
            "enzyme=0 substrate=0\n",
            "{'primary': 'O15297', 'secondary': ['Q53XP4', 'Q6P991', 'Q8IVR6'], 'protein': 'Protein phosphatase 1D', 'genes': ['PPM1D'], 'organism': 'Homo sapiens'}\n",
            "{'primary': 'Q13950', 'secondary': ['O14614', 'O14615', 'O95181'], 'protein': 'Runt-related transcription factor 2', 'genes': ['RUNX2'], 'organism': 'Homo sapiens'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run with Graphical Interface"
      ],
      "metadata": {
        "id": "hvTUzr7rSw9O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from flask import Flask, request, render_template_string\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# ================== 1. Read ngrok token and open tunnel ==================\n",
        "with open('ngrok_authtoken.txt', 'r') as f:\n",
        "    NGROK_AUTH_TOKEN = f.read().strip()\n",
        "\n",
        "ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "port = 5000\n",
        "public_url = ngrok.connect(port).public_url\n",
        "print(f\"Public URL: {public_url}\")\n",
        "\n",
        "# ================== 2. Initialize Flask app ==================\n",
        "app = Flask(__name__)\n",
        "app.secret_key = 'the_secret_key'\n",
        "\n",
        "# ================== 3. Global variables ==================\n",
        "#     Store: abstract text, a combined list of reasoning+result (reason_result_list),\n",
        "#     and final lists for enzyme and substrate IDs\n",
        "abstract_text = \"\"\n",
        "reason_result_list = []  # Each element: {\"reasoning\": \"...\", \"result\": \"...\"}\n",
        "enzyme_list = []\n",
        "substrate_list = []\n",
        "\n",
        "# ================== 4. Three-column layout HTML template ==================\n",
        "HTML_TEMPLATE = r\"\"\"\n",
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "    <meta charset=\"utf-8\">\n",
        "    <title>Flask + pyngrok Demo</title>\n",
        "    <style>\n",
        "        /* Overall Page & Body */\n",
        "        body {\n",
        "            margin: 0;\n",
        "            padding: 0;\n",
        "            font-family: \"Segoe UI\", \"Roboto\", \"Helvetica Neue\", Arial, sans-serif;\n",
        "            background-color: #f0f2f5; /* Light background, akin to ChatGPT day mode */\n",
        "            color: #333;\n",
        "            height: 100vh; /* Ensures body fills screen height */\n",
        "        }\n",
        "\n",
        "        /* Container that holds the three columns */\n",
        "        .container {\n",
        "            display: flex;\n",
        "            flex-direction: row;\n",
        "            width: 100%;\n",
        "            height: 100%;\n",
        "            box-sizing: border-box;\n",
        "        }\n",
        "\n",
        "        /* Left, Middle, and Right Columns */\n",
        "        .left, .middle, .right {\n",
        "            padding: 20px;\n",
        "            overflow-y: auto;\n",
        "            box-sizing: border-box;\n",
        "            background-color: #fff; /* White background for contrast */\n",
        "        }\n",
        "        .left {\n",
        "            flex: 0 0 25%;\n",
        "            border-right: 1px solid #e0e0e0;\n",
        "        }\n",
        "        .middle {\n",
        "            flex: 1;\n",
        "            border-right: 1px solid #e0e0e0;\n",
        "        }\n",
        "        .right {\n",
        "            flex: 0 0 25%;\n",
        "        }\n",
        "\n",
        "        /* Headings in columns */\n",
        "        h3 {\n",
        "            margin: 0 0 10px 0;\n",
        "            font-size: 18px;\n",
        "            font-weight: bold;\n",
        "            color: #333;\n",
        "        }\n",
        "\n",
        "        /* Abstract box and Reasoning/Result boxes */\n",
        "        .abstract-box,\n",
        "        .reason-result-box {\n",
        "            margin-top: 5px;\n",
        "            padding: 15px;\n",
        "            background-color: #fff;\n",
        "            border: 1px solid #e0e0e0;\n",
        "            border-radius: 5px;\n",
        "            white-space: pre-wrap;\n",
        "        }\n",
        "\n",
        "        /* Smaller label-like headings for \"Reasoning\" and \"Result\" */\n",
        "        .title {\n",
        "            font-size: 14px;\n",
        "            font-weight: bold;\n",
        "            margin-bottom: 5px;\n",
        "            color: #555;\n",
        "        }\n",
        "\n",
        "        /* Horizontal line divider inside reason-result-box */\n",
        "        hr {\n",
        "            border: none;\n",
        "            border-top: 1px solid #eee;\n",
        "            margin: 5px 0;\n",
        "        }\n",
        "\n",
        "        /* Table for final enzyme/substrate info */\n",
        "        table {\n",
        "            border-collapse: collapse;\n",
        "            margin-top: 10px;\n",
        "            width: 100%;\n",
        "            background-color: #fff;\n",
        "        }\n",
        "        td, th {\n",
        "            border: 1px solid #e0e0e0;\n",
        "            padding: 8px;\n",
        "            text-align: left;\n",
        "            font-size: 14px;\n",
        "        }\n",
        "\n",
        "        /* Form elements */\n",
        "        form {\n",
        "            margin-top: 10px;\n",
        "        }\n",
        "        label {\n",
        "            font-size: 14px;\n",
        "            margin-bottom: 5px;\n",
        "            display: inline-block;\n",
        "        }\n",
        "        input[type=\"text\"] {\n",
        "            padding: 6px;\n",
        "            font-size: 14px;\n",
        "            margin-top: 5px;\n",
        "            box-sizing: border-box;\n",
        "            border: 1px solid #ccc;\n",
        "            border-radius: 4px;\n",
        "        }\n",
        "        button {\n",
        "            cursor: pointer;\n",
        "            padding: 8px 16px;\n",
        "            font-size: 14px;\n",
        "            border: none;\n",
        "            border-radius: 4px;\n",
        "            background-color: #4caf50;\n",
        "            color: #fff;\n",
        "        }\n",
        "        button:hover {\n",
        "            background-color: #43a047;\n",
        "        }\n",
        "    </style>\n",
        "</head>\n",
        "<body>\n",
        "<div class=\"container\">\n",
        "\n",
        "    <!-- Left Column: Enter PMID & retrieve abstract -->\n",
        "    <div class=\"left\">\n",
        "        <h3>Enter PMID</h3>\n",
        "        <form method=\"POST\">\n",
        "            <label for=\"pmid\">PMID:</label><br>\n",
        "            <input type=\"text\" id=\"pmid\" name=\"pmid\" style=\"width:80%;\" required\n",
        "            value=\"{{ current_pmid }}\">\n",
        "            <br><br>\n",
        "            <button type=\"submit\" name=\"action\" value=\"search\">Search Abstract</button>\n",
        "        </form>\n",
        "\n",
        "        {% if abstract_text %}\n",
        "        <div class=\"abstract-box\">\n",
        "            <strong>Abstract Retrieved:</strong><br>\n",
        "            {{ abstract_text }}\n",
        "        </div>\n",
        "        <form method=\"POST\">\n",
        "            <input type=\"hidden\" name=\"pmid\" value=\"{{ current_pmid }}\">\n",
        "            <button type=\"submit\" name=\"action\" value=\"extract\">Extract Information</button>\n",
        "        </form>\n",
        "        {% endif %}\n",
        "    </div>\n",
        "\n",
        "    <!-- Middle Column: Combined Reasoning + Result in one box -->\n",
        "    <div class=\"middle\">\n",
        "        <h3>Reasoning &amp; Results</h3>\n",
        "        {% for rr in reason_result_list %}\n",
        "        <div class=\"reason-result-box\">\n",
        "            <div class=\"title\">Reasoning:</div>\n",
        "            {{ rr.reasoning }}\n",
        "            <hr>\n",
        "            <div class=\"title\">Result:</div>\n",
        "            {{ rr.result }}\n",
        "        </div>\n",
        "        {% endfor %}\n",
        "    </div>\n",
        "\n",
        "    <!-- Right Column: Display final enzyme_list & substrate_list -->\n",
        "    <div class=\"right\">\n",
        "        <h3>Final Enzyme / Substrate Information</h3>\n",
        "        <table>\n",
        "            <tr>\n",
        "                <th>Enzyme</th>\n",
        "                <th>Substrate</th>\n",
        "            </tr>\n",
        "            {% for e, s in enz_sub_pairs %}\n",
        "            <tr>\n",
        "                <td>{{ e }}</td>\n",
        "                <td>{{ s }}</td>\n",
        "            </tr>\n",
        "            {% endfor %}\n",
        "        </table>\n",
        "    </div>\n",
        "\n",
        "</div>\n",
        "</body>\n",
        "</html>\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# ================== 5. Main route: Three-column website ==================\n",
        "@app.route(\"/\", methods=[\"GET\", \"POST\"])\n",
        "def index():\n",
        "    global abstract_text, reason_result_list, enzyme_list, substrate_list\n",
        "\n",
        "    current_pmid = \"\"\n",
        "\n",
        "    if request.method == 'POST':\n",
        "        action = request.form.get(\"action\", \"\")\n",
        "        pmid_input = request.form.get(\"pmid\", \"\").strip()\n",
        "        current_pmid = pmid_input  # Used for display if user re-renders the page\n",
        "\n",
        "        if action == \"search\":\n",
        "            # ========== 1) Retrieve and extract abstract by PMID ==========\n",
        "            #     Clear old reason/result data each time a new search is done\n",
        "            try:\n",
        "                retriever = ArticleRetriever()\n",
        "                res, html_content, code = retriever.request_article(pmid_input)\n",
        "                cleaned = extract_abstract(html_content)\n",
        "                abstract_text = cleaned\n",
        "\n",
        "                reason_result_list.clear()\n",
        "                enzyme_list.clear()\n",
        "                substrate_list.clear()\n",
        "\n",
        "            except Exception as e:\n",
        "                # If retrieval fails, show it in the abstract box\n",
        "                abstract_text = f\"Failed to retrieve abstract: {str(e)}\"\n",
        "\n",
        "        elif action == \"extract\" and abstract_text:\n",
        "            # ========== 2) Use the core backend code to extract/parse ==========\n",
        "            try:\n",
        "                pmid = pmid_input\n",
        "\n",
        "                # Step 1: Retrieve & Abstract\n",
        "                retriever = ArticleRetriever()\n",
        "                res, html_content, code = retriever.request_article(pmid)\n",
        "                cleaned_text = extract_abstract(html_content)\n",
        "\n",
        "                # Show the abstract in Reasoning/Result as well\n",
        "                reason_result_list.append({\n",
        "                    \"reasoning\": \"Extracted the abstract from article\",\n",
        "                    \"result\": f\"Abstract:\\n{cleaned_text}\"\n",
        "                })\n",
        "\n",
        "                # Step 2: Set GOOGLE_API_KEY\n",
        "                os.environ[\"GOOGLE_API_KEY\"] = os.environ.get(\"GEMINI_15_API_KEY\", None)\n",
        "\n",
        "                parser_extract_enzyme_substrate_pairs = PydanticOutputParser(pydantic_object=RelationshipList)\n",
        "                llm = ChatGoogleGenerativeAI(model=\"models/gemini-1.5-pro-latest\", temperature=0)\n",
        "                output_parser_extract_enzyme_substrate_pairs = OutputFixingParser.from_llm(parser=parser_extract_enzyme_substrate_pairs, llm=llm)\n",
        "                chain_extract_enzyme_substrate_pairs = LLMChain(llm=llm, prompt=prompt_extract_enzyme_substrate_pairs, output_parser=output_parser_extract_enzyme_substrate_pairs)\n",
        "\n",
        "                result_extract_enzyme_substrate_pairs = extract_enzyme_substrate_pairs(llm, chain_extract_enzyme_substrate_pairs, prompt_extract_enzyme_substrate_pairs, cleaned_text)\n",
        "\n",
        "                # Combine reasoning & result for the first extraction\n",
        "                pairs_str = \"\"\n",
        "                for pair in result_extract_enzyme_substrate_pairs.pairs:\n",
        "                    pairs_str += f\"{pair.enzyme} acts on {pair.substrate}\\n\"\n",
        "                reason_result_list.append({\n",
        "                    \"reasoning\": result_extract_enzyme_substrate_pairs.reasoning,\n",
        "                    \"result\": pairs_str\n",
        "                })\n",
        "\n",
        "                # Step 3: Initialize enzyme_list / substrate_list\n",
        "                enzyme_list = []\n",
        "                substrate_list = []\n",
        "\n",
        "                # For each pair, do UniProt searching, matching, etc.\n",
        "                for pair in result_extract_enzyme_substrate_pairs.pairs:\n",
        "                    try:\n",
        "                        # Part A: Searching UniProt\n",
        "                        text_uniprot_enzyme = query_uniprot_all(pair.enzyme)\n",
        "                        text_uniprot_substr = query_uniprot_all(pair.substrate)\n",
        "                        reason_result_list.append({\n",
        "                            \"reasoning\": \"Searched UniProt (uniprot.org) for possible matches\",\n",
        "                            \"result\": f\"\"\"\\n**Enzyme search results**:\n",
        "    {text_uniprot_enzyme[0]}\n",
        "    \\n**Substrate search results**:\n",
        "    {text_uniprot_substr[0]}\"\"\"\n",
        "                        })\n",
        "\n",
        "                        # Part B: Matching best UniProt indices\n",
        "                        parser_match_best_uniprot_indices = PydanticOutputParser(pydantic_object=MatchSelection)\n",
        "                        output_parser_match_best_uniprot_indices = OutputFixingParser.from_llm(parser=parser_match_best_uniprot_indices, llm=llm)\n",
        "                        chain_match_best_uniprot_indices = LLMChain(llm=llm, prompt=prompt_match_best_uniprot_indices, output_parser=output_parser_match_best_uniprot_indices)\n",
        "\n",
        "                        result_match_best_uniprot_indices = match_best_uniprot_indices(\n",
        "                            llm=llm,\n",
        "                            chain=chain_match_best_uniprot_indices,\n",
        "                            prompt_template=prompt_match_best_uniprot_indices,\n",
        "                            full_text=cleaned_text,\n",
        "                            enzyme_name=pair.enzyme,\n",
        "                            substrate_name=pair.substrate,\n",
        "                            enzyme_uniprot_results=text_uniprot_enzyme[0],\n",
        "                            substrate_uniprot_results=text_uniprot_substr[0]\n",
        "                        )\n",
        "                        reason_result_list.append({\n",
        "                            \"reasoning\": result_match_best_uniprot_indices.reasoning,\n",
        "                            \"result\": f\"Use search_result[{result_match_best_uniprot_indices.pairs.enzyme}] as the Enzyme and search_result[{result_match_best_uniprot_indices.pairs.substrate}] as the Substrate.\"\n",
        "                        })\n",
        "\n",
        "                        # Finally, store the chosen IDs\n",
        "                        best_e_id = query_uniprot_all(pair.enzyme)[1][result_match_best_uniprot_indices.pairs.enzyme]\n",
        "                        best_s_id = query_uniprot_all(pair.substrate)[1][result_match_best_uniprot_indices.pairs.substrate]\n",
        "                        enzyme_list.append(best_e_id)\n",
        "                        substrate_list.append(best_s_id)\n",
        "                    except Exception as ex:\n",
        "                        pass\n",
        "\n",
        "                # Summarize final enzyme_list and substrate_list\n",
        "                reason_result_list.append({\n",
        "                    \"reasoning\": \"Collected final enzyme and substrate IDs\",\n",
        "                    \"result\": f\"Enzyme List: {enzyme_list}\\nSubstrate List: {substrate_list}\"\n",
        "                })\n",
        "                # ---------------------------------------------------------\n",
        "\n",
        "            except Exception as ex:\n",
        "                reason_result_list.append({\n",
        "                    \"reasoning\": \"Error occurred while extracting information\",\n",
        "                    \"result\": str(ex)\n",
        "                })\n",
        "\n",
        "    # Construct the right-column pairs of (enzyme_list, substrate_list)\n",
        "    enz_sub_pairs = list(zip(enzyme_list, substrate_list))\n",
        "\n",
        "    return render_template_string(\n",
        "        HTML_TEMPLATE,\n",
        "        abstract_text=abstract_text,\n",
        "        reason_result_list=reason_result_list,\n",
        "        enz_sub_pairs=enz_sub_pairs,\n",
        "        current_pmid=current_pmid\n",
        "    )\n",
        "\n",
        "# ================== 7. Entry point: Run the Flask app ==================\n",
        "if __name__ == \"__main__\":\n",
        "    app.run(port=port)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDXJ0eU9Pq09",
        "outputId": "ee3f7a99-d296-46a4-e292-ce16e33fc2ea"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Public URL: https://3e4d-35-229-229-180.ngrok-free.app\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug:127.0.0.1 - - [26/Mar/2025 21:09:38] \"GET / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [26/Mar/2025 21:09:38] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "make get request to https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/22065775/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [26/Mar/2025 21:09:48] \"POST / HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "make get request to https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/22065775/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [26/Mar/2025 21:10:13] \"POST / HTTP/1.1\" 200 -\n"
          ]
        }
      ]
    }
  ]
}